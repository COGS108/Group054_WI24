{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If you lost points on the last checkpoint you can get them back by responding to TA/IA feedback**  \n",
    "\n",
    "Update/change the relevant sections where you lost those points, make sure you respond on GitHub Issues to your TA/IA to call their attention to the changes you made here.\n",
    "\n",
    "Please update your Timeline... no battle plan survives contact with the enemy, so make sure we understand how your plans have changed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 108 - EDA Checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Names\n",
    "\n",
    "- Ant Man\n",
    "- Hulk\n",
    "- Iron Man\n",
    "- Thor\n",
    "- Wasp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Research Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  Include a specific, clear data science question.\n",
    "-  Make sure what you're measuring (variables) to answer the question is clear\n",
    "\n",
    "What is your research question? Include the specific question you're setting out to answer. This question should be specific, answerable with data, and clear. A general question with specific subquestions is permitted. (1-2 sentences)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background and Prior Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Include a general introduction to your topic\n",
    "- Include explanation of what work has been done previously\n",
    "- Include citations or links to previous work\n",
    "\n",
    "This section will present the background and context of your topic and question in a few paragraphs. Include a general introduction to your topic and then describe what information you currently know about the topic after doing your initial research. Include references to other projects who have asked similar questions or approached similar problems. Explain what others have learned in their projects.\n",
    "\n",
    "Find some relevant prior work, and reference those sources, summarizing what each did and what they learned. Even if you think you have a totally novel question, find the most similar prior work that you can and discuss how it relates to your project.\n",
    "\n",
    "References can be research publications, but they need not be. Blogs, GitHub repositories, company websites, etc., are all viable references if they are relevant to your project. It must be clear which information comes from which references. (2-3 paragraphs, including at least 2 references)\n",
    "\n",
    " **Use inline citation through HTML footnotes to specify which references support which statements** \n",
    "\n",
    "For example: After government genocide in the 20th century, real birds were replaced with surveillance drones designed to look just like birds.<a name=\"cite_ref-1\"></a>[<sup>1</sup>](#cite_note-1) Use a minimum of 2 or 3 citations, but we prefer more.<a name=\"cite_ref-2\"></a>[<sup>2</sup>](#cite_note-2) You need enough to fully explain and back up important facts. \n",
    "\n",
    "Note that if you click a footnote number in the paragraph above it will transport you to the proper entry in the footnotes list below.  And if you click the ^ in the footnote entry, it will return you to the place in the main text where the footnote is made.\n",
    "\n",
    "To understand the HTML here, `<a name=\"#...\"> </a>` is a tag that allows you produce a named reference for a given location.  Markdown has the construciton `[text with hyperlink](#named reference)` that will produce a clickable link that transports you the named reference.\n",
    "\n",
    "1. <a name=\"cite_note-1\"></a> [^](#cite_ref-1) Lorenz, T. (9 Dec 2021) Birds Aren’t Real, or Are They? Inside a Gen Z Conspiracy Theory. *The New York Times*. https://www.nytimes.com/2021/12/09/technology/birds-arent-real-gen-z-misinformation.html \n",
    "2. <a name=\"cite_note-2\"></a> [^](#cite_ref-2) Also refs should be important to the background, not some randomly chosen vaguely related stuff. Include a web link if possible in refs as above.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Include your team's hypothesis\n",
    "- Ensure that this hypothesis is clear to readers\n",
    "- Explain why you think this will be the outcome (what was your thinking?)\n",
    "\n",
    "What is your main hypothesis/predictions about what the answer to your question is? Briefly explain your thinking. (2-3 sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data overview\n",
    "\n",
    "For each dataset include the following information\n",
    "- Dataset #1\n",
    "  - Dataset Name:\n",
    "  - Link to the dataset:\n",
    "  - Number of observations:\n",
    "  - Number of variables:\n",
    "- Dataset #2 (if you have more than one!)\n",
    "  - Dataset Name:\n",
    "  - Link to the dataset:\n",
    "  - Number of observations:\n",
    "  - Number of variables:\n",
    "- etc\n",
    "\n",
    "Now write 2 - 5 sentences describing each dataset here. Include a short description of the important variables in the dataset; what the metrics and datatypes are, what concepts they may be proxies for. Include information about how you would need to wrangle/clean/preprocess the dataset\n",
    "\n",
    "If you plan to use multiple datasets, add a few sentences about how you plan to combine these datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset #1 Emergency Management Performance Grants "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leofl\\AppData\\Local\\Temp\\ipykernel_13096\\558211804.py:42: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  df_grouped = df.groupby(by = ['state', 'reportingPeriod']).sum()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>year</th>\n",
       "      <th>funding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AL</td>\n",
       "      <td>2019</td>\n",
       "      <td>5728503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AL</td>\n",
       "      <td>2020</td>\n",
       "      <td>5810021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AL</td>\n",
       "      <td>2021</td>\n",
       "      <td>7446681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AL</td>\n",
       "      <td>2022</td>\n",
       "      <td>6681181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AK</td>\n",
       "      <td>2019</td>\n",
       "      <td>3093229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>WI</td>\n",
       "      <td>2022</td>\n",
       "      <td>7311711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>WY</td>\n",
       "      <td>2019</td>\n",
       "      <td>2991828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>WY</td>\n",
       "      <td>2020</td>\n",
       "      <td>3033266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>WY</td>\n",
       "      <td>2021</td>\n",
       "      <td>3889834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>WY</td>\n",
       "      <td>2022</td>\n",
       "      <td>3455841</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    state  year  funding\n",
       "0      AL  2019  5728503\n",
       "1      AL  2020  5810021\n",
       "2      AL  2021  7446681\n",
       "3      AL  2022  6681181\n",
       "4      AK  2019  3093229\n",
       "..    ...   ...      ...\n",
       "195    WI  2022  7311711\n",
       "196    WY  2019  2991828\n",
       "197    WY  2020  3033266\n",
       "198    WY  2021  3889834\n",
       "199    WY  2022  3455841\n",
       "\n",
       "[200 rows x 3 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 10)\n",
    "\n",
    "url = 'Data/EmergencyManagementPerformanceGrants.csv'\n",
    "df = pd.read_csv(url)\n",
    "df['state'].unique()\n",
    "df_not_state = df['state'].str.contains('Puerto Rico|American Samoa|District of Columbia|Northern Mariana Islands|Guam|Virgin Islands')\n",
    "df = df[~df_not_state] #filter to only include US states\n",
    "df['state'].unique().size #check to see that our state column only has 50 values\n",
    "\n",
    "def standardize_reportingPeriod(string):\n",
    "    \n",
    "    string = string.lower().strip()\n",
    "    \n",
    "    if '2014' in string:\n",
    "        output = 2014\n",
    "    elif '2015' in string:\n",
    "        output = 2015\n",
    "    elif '2016' in string:\n",
    "        output = 2016\n",
    "    elif '2017' in string:\n",
    "        output = 2017\n",
    "    elif '2018' in string:\n",
    "        output = 2018\n",
    "    elif '2019' in string:\n",
    "        output = 2019\n",
    "    elif '2020' in string:\n",
    "        output = 2020\n",
    "    elif '2021' in string:\n",
    "        output = 2021\n",
    "    elif '2022' in string:\n",
    "        output = 2022\n",
    "    # Otherwise, if uncaught - keep as is\n",
    "    else:\n",
    "        output = string\n",
    "    \n",
    "    return output\n",
    "\n",
    "df['reportingPeriod'] = df['reportingPeriod'].apply(standardize_reportingPeriod)\n",
    "df = df.query('reportingPeriod >= 2019') #filter so lowest year is 2017 to match other data\n",
    "\n",
    "df_grouped = df.groupby(by = ['state', 'reportingPeriod']).sum()\n",
    "df_grouped = df_grouped.reset_index()\n",
    "df_grouped = df_grouped.rename(columns = {'reportingPeriod': 'year', 'fundingAmount' : 'funding'})\n",
    "df_grouped['funding'] = df_grouped['funding'].astype(int)\n",
    "\n",
    "us_state_to_abbrev = {\n",
    "    \"Alabama\": \"AL\", \"Alaska\": \"AK\", \"Arizona\": \"AZ\", \"Arkansas\": \"AR\", \"California\": \"CA\",\n",
    "    \"Colorado\": \"CO\", \"Connecticut\": \"CT\", \"Delaware\": \"DE\", \"Florida\": \"FL\", \"Georgia\": \"GA\",\n",
    "    \"Hawaii\": \"HI\", \"Idaho\": \"ID\", \"Illinois\": \"IL\", \"Indiana\": \"IN\", \"Iowa\": \"IA\",\n",
    "    \"Kansas\": \"KS\", \"Kentucky\": \"KY\", \"Louisiana\": \"LA\", \"Maine\": \"ME\", \"Maryland\": \"MD\",\n",
    "    \"Massachusetts\": \"MA\", \"Michigan\": \"MI\", \"Minnesota\": \"MN\", \"Mississippi\": \"MS\", \"Missouri\": \"MO\",\n",
    "    \"Montana\": \"MT\", \"Nebraska\": \"NE\", \"Nevada\": \"NV\", \"New hampshire\": \"NH\", \"New jersey\": \"NJ\",\n",
    "    \"New mexico\": \"NM\", \"New york\": \"NY\", \"North carolina\": \"NC\", \"North dakota\": \"ND\", \"Ohio\": \"OH\",\n",
    "    \"Oklahoma\": \"OK\", \"Oregon\": \"OR\", \"Pennsylvania\": \"PA\", \"Rhode island\": \"RI\", \"South carolina\": \"SC\",\n",
    "    \"South dakota\": \"SD\", \"Tennessee\": \"TN\", \"Texas\": \"TX\", \"Utah\": \"UT\", \"Vermont\": \"VT\",\n",
    "    \"Virginia\": \"VA\", \"Washington\": \"WA\", \"West virginia\": \"WV\", \"Wisconsin\": \"WI\", \"Wyoming\": \"WY\"\n",
    "}\n",
    "\n",
    "df_grouped['state'] = df_grouped['state'].str.lower().str.capitalize().map(us_state_to_abbrev)\n",
    "EMPG = df_grouped #naming to something we will remember\n",
    "EMPG['year'] = EMPG['year'].astype(int) # change to integers\n",
    "EMPG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset #2 Disaster Declarations by State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>year</th>\n",
       "      <th>disasters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AL</td>\n",
       "      <td>2019</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AL</td>\n",
       "      <td>2020</td>\n",
       "      <td>257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AL</td>\n",
       "      <td>2021</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AL</td>\n",
       "      <td>2022</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AK</td>\n",
       "      <td>2019</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>WI</td>\n",
       "      <td>2022</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>WY</td>\n",
       "      <td>2019</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>WY</td>\n",
       "      <td>2020</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>WY</td>\n",
       "      <td>2021</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>WY</td>\n",
       "      <td>2022</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    state  year  disasters\n",
       "0      AL  2019         36\n",
       "1      AL  2020        257\n",
       "2      AL  2021         30\n",
       "3      AL  2022          2\n",
       "4      AK  2019          9\n",
       "..    ...   ...        ...\n",
       "195    WI  2022          0\n",
       "196    WY  2019          0\n",
       "197    WY  2020         51\n",
       "198    WY  2021          0\n",
       "199    WY  2022          0\n",
       "\n",
       "[200 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url2 = 'Data/DisasterDeclarationsSummaries.csv'\n",
    "df2= pd.read_csv(url2)\n",
    "\n",
    "df2 = df2.query('2023 > fyDeclared >= 2019 ') # make sure to include equals so 2017 included\n",
    "df2.sort_values(by = 'fyDeclared', ascending = True) # set to true so make sure have correct info\n",
    "df2 = df2.groupby(by = ['state', 'fyDeclared']).size().reset_index(name= 'disasters') # use size for num of disasters instead of sum & give column name\n",
    "df2 = df2.rename(columns={'fyDeclared': 'year'})\n",
    "valid_states = ['AL', 'AK', 'AZ', 'AR', 'CA', 'CO', 'CT', 'DE', 'FL', 'GA', \n",
    "                'HI', 'ID', 'IL', 'IN', 'IA', 'KS', 'KY', 'LA', 'ME', 'MD', \n",
    "                'MA', 'MI', 'MN', 'MS', 'MO', 'MT', 'NE', 'NV', 'NH', 'NJ', \n",
    "                'NM', 'NY', 'NC', 'ND', 'OH', 'OK', 'OR', 'PA', 'RI', 'SC', \n",
    "                'SD', 'TN', 'TX', 'UT', 'VT', 'VA', 'WA', 'WV', 'WI', 'WY']\n",
    "\n",
    "# Filter the DataFrame to only include rows where the state code is in the list of valid states\n",
    "df2 = df2[df2['state'].isin(valid_states)]\n",
    "df2\n",
    "\n",
    "# states didnt have disasters every year so we need to create columns with 0 for years no disasters were declared\n",
    "import itertools\n",
    "\n",
    "years = [2019, 2020, 2021, 2022]\n",
    "combinations = list(itertools.product(valid_states, years)) # Use itertools.product to get all combinations of states and years -- this works like a double sum where the valid states is fixed and its looking at all the states to match\n",
    "combinations\n",
    "df2_combinations = pd.DataFrame(combinations, columns=['state', 'year'])\n",
    "df2_combinations\n",
    "df2_merged = pd.merge(df2_combinations, df2, on = ['state', 'year'], how = 'left')# how on left so that df2_combinations has all rows saved and df2 added -- state and year pairs will get na values\n",
    "df2_merged['disasters'].fillna(0, inplace= True) #in place so a new data frame is not created and old one is kept\n",
    "df2_merged['disasters'] = df2_merged['disasters'].astype(int) # astype converts to a integer\n",
    "disasters =  df2_merged #naming to something we will remember\n",
    "disasters['year'] = disasters['year'].astype(int) # change to integers\n",
    "disasters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset #3 State Historical Political Leaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>year</th>\n",
       "      <th>party</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AL</td>\n",
       "      <td>2019</td>\n",
       "      <td>REPUBLICAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AL</td>\n",
       "      <td>2020</td>\n",
       "      <td>REPUBLICAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AL</td>\n",
       "      <td>2021</td>\n",
       "      <td>REPUBLICAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AL</td>\n",
       "      <td>2022</td>\n",
       "      <td>REPUBLICAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AK</td>\n",
       "      <td>2019</td>\n",
       "      <td>REPUBLICAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>WI</td>\n",
       "      <td>2022</td>\n",
       "      <td>REPUBLICAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>WY</td>\n",
       "      <td>2019</td>\n",
       "      <td>REPUBLICAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>WY</td>\n",
       "      <td>2020</td>\n",
       "      <td>REPUBLICAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>WY</td>\n",
       "      <td>2021</td>\n",
       "      <td>REPUBLICAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>WY</td>\n",
       "      <td>2022</td>\n",
       "      <td>REPUBLICAN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>204 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    state  year       party\n",
       "0      AL  2019  REPUBLICAN\n",
       "1      AL  2020  REPUBLICAN\n",
       "2      AL  2021  REPUBLICAN\n",
       "3      AL  2022  REPUBLICAN\n",
       "4      AK  2019  REPUBLICAN\n",
       "..    ...   ...         ...\n",
       "199    WI  2022  REPUBLICAN\n",
       "200    WY  2019  REPUBLICAN\n",
       "201    WY  2020  REPUBLICAN\n",
       "202    WY  2021  REPUBLICAN\n",
       "203    WY  2022  REPUBLICAN\n",
       "\n",
       "[204 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url3 = 'Data/1976-2022-house.csv'\n",
    "election_data= pd.read_csv(url3)\n",
    "\n",
    "elections_post_2017 = election_data[election_data['year'] > 2019]\n",
    "relevant_elections = elections_post_2017[elections_post_2017['party'].isin(['DEMOCRAT', 'REPUBLICAN'])]\n",
    "grouped_elections = relevant_elections.groupby(['state', 'year', 'party'])['candidatevotes'].sum().reset_index()\n",
    "winning_party = grouped_elections.sort_values('candidatevotes', ascending=False).drop_duplicates(['state', 'year'])\n",
    "winning_party = winning_party.sort_values(by = 'state')\n",
    "winning_party = winning_party.drop(columns= 'candidatevotes')\n",
    "\n",
    "\n",
    "#df.reindex -- confrom DF to a new index w. optional filling -- places NA in locastions having no value in teh previous index\n",
    "# we reindex the winning_party data frame to do this\n",
    "# we use pd.MultiIndex.from_product instead of iterools.prodcut(state, year) bcs it returns a list instead of a multiindex\n",
    "winning_party_indexed = winning_party.set_index(['state', 'year'])\n",
    "state = winning_party_indexed.index.levels[0]\n",
    "year = [2019,2020,2021,2022]\n",
    "multi_index = pd.MultiIndex.from_product([state, year])\n",
    "winning_party_indexed = winning_party_indexed.reindex(multi_index)\n",
    "winning_party_indexed_filled = winning_party_indexed.groupby(level=0).fillna(method='ffill').fillna(method='bfill').reset_index()\n",
    "winning_party_indexed_filled = winning_party_indexed_filled.rename(columns = {'level_1' : 'year'})\n",
    "\n",
    "#the rest of our data tables use state postal codes instead of the full names\n",
    "#using a dictionary I found on GitHub we can map these states to their postal codes\n",
    "us_state_to_abbrev = {\n",
    "    \"Alabama\": \"AL\", \"Alaska\": \"AK\", \"Arizona\": \"AZ\", \"Arkansas\": \"AR\", \"California\": \"CA\",\n",
    "    \"Colorado\": \"CO\", \"Connecticut\": \"CT\", \"Delaware\": \"DE\", \"Florida\": \"FL\", \"Georgia\": \"GA\",\n",
    "    \"Hawaii\": \"HI\", \"Idaho\": \"ID\", \"Illinois\": \"IL\", \"Indiana\": \"IN\", \"Iowa\": \"IA\",\n",
    "    \"Kansas\": \"KS\", \"Kentucky\": \"KY\", \"Louisiana\": \"LA\", \"Maine\": \"ME\", \"Maryland\": \"MD\",\n",
    "    \"Massachusetts\": \"MA\", \"Michigan\": \"MI\", \"Minnesota\": \"MN\", \"Mississippi\": \"MS\", \"Missouri\": \"MO\",\n",
    "    \"Montana\": \"MT\", \"Nebraska\": \"NE\", \"Nevada\": \"NV\", \"New hampshire\": \"NH\", \"New jersey\": \"NJ\",\n",
    "    \"New mexico\": \"NM\", \"New york\": \"NY\", \"North carolina\": \"NC\", \"North dakota\": \"ND\", \"Ohio\": \"OH\",\n",
    "    \"Oklahoma\": \"OK\", \"Oregon\": \"OR\", \"Pennsylvania\": \"PA\", \"Rhode island\": \"RI\", \"South carolina\": \"SC\",\n",
    "    \"South dakota\": \"SD\", \"Tennessee\": \"TN\", \"Texas\": \"TX\", \"Utah\": \"UT\", \"Vermont\": \"VT\",\n",
    "    \"Virginia\": \"VA\", \"Washington\": \"WA\", \"West virginia\": \"WV\", \"Wisconsin\": \"WI\", \"Wyoming\": \"WY\"\n",
    "}\n",
    "\n",
    "winning_party_indexed_filled['state'] = winning_party_indexed_filled['state'].str.lower().str.capitalize().map(us_state_to_abbrev)\n",
    "state_political_leaning = winning_party_indexed_filled #naming to something will actually remember\n",
    "state_political_leaning['year'] = state_political_leaning['year'].astype('int32')\n",
    "state_political_leaning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset #4 GDP by State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>year</th>\n",
       "      <th>GDP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AL</td>\n",
       "      <td>2019</td>\n",
       "      <td>234526.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>AL</td>\n",
       "      <td>2020</td>\n",
       "      <td>235118.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>AL</td>\n",
       "      <td>2022</td>\n",
       "      <td>281569.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>AL</td>\n",
       "      <td>2021</td>\n",
       "      <td>257986.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>AK</td>\n",
       "      <td>2022</td>\n",
       "      <td>65698.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>WI</td>\n",
       "      <td>2019</td>\n",
       "      <td>347398.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>WY</td>\n",
       "      <td>2020</td>\n",
       "      <td>36675.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>WY</td>\n",
       "      <td>2019</td>\n",
       "      <td>39971.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>WY</td>\n",
       "      <td>2021</td>\n",
       "      <td>42176.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>WY</td>\n",
       "      <td>2022</td>\n",
       "      <td>49080.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    state  year       GDP\n",
       "0      AL  2019  234526.4\n",
       "50     AL  2020  235118.3\n",
       "150    AL  2022  281569.0\n",
       "100    AL  2021  257986.5\n",
       "151    AK  2022   65698.8\n",
       "..    ...   ...       ...\n",
       "48     WI  2019  347398.6\n",
       "99     WY  2020   36675.5\n",
       "49     WY  2019   39971.4\n",
       "149    WY  2021   42176.2\n",
       "199    WY  2022   49080.6\n",
       "\n",
       "[200 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Log onto the BEA website (Bureau of Economic Analysis), the official site for government data.\n",
    "# Navigate to the \"Data\" section, select \"GDP,\" and then choose \"GDP by State.\"\n",
    "# Go to \"Interactive Data\" and select \"Interactive Tables: GDP by State.\"\n",
    "# Choose \"ANNUAL GROSS DOMESTIC PRODUCT (GDP) BY STATE,\" then \"SAGDP2 GDP in current dollars.\"\n",
    "# Select the United States, and view all statistics in the table.\n",
    "# In the resulting table, select the first row's line code where the description is \"all industry total.\"\n",
    "# The resulting table displays the GDP by state in millions of current dollars, with data collected from 2017 to 2022.\n",
    "\n",
    "url4 =  \"Data/GDP by state (2017-2022).csv\"\n",
    "\n",
    "df4 = pd.read_csv(url4, skiprows = 3) #skip first 3 rows because they are a description\n",
    "df4 = df4.drop(columns = ['GeoFips', '2017', '2018'])\n",
    "df4 = df4.rename(columns= {'GeoName': 'state'})\n",
    "df4_bad_GeoName = df4['state'].str.contains('District of Columbia|New England|nited States *|Mideast|Great Lakes|Plains|Southeast|Southwest|nan|Rocky Mountain|Far West').fillna(False) #dealing with NA values\n",
    "df4 = df4[~ df4_bad_GeoName] #this removes all the regions and territories we don't care about \n",
    "indexes_to_drop = df4.iloc[-4:].index #get the last 4 rows index using iloc\n",
    "df4 = df4.drop(indexes_to_drop)\n",
    "melted_df = pd.melt(df4, id_vars=['state'], value_vars=['2019', '2020', '2021', '2022'], var_name='year', value_name='amount')\n",
    "melted_df = melted_df.sort_values('state')\n",
    "melted_df\n",
    "\n",
    "#using the same code I used on the state leaning dat set we change the years to their postal codes\n",
    "\n",
    "us_state_to_abbrev = {\n",
    "    \"Alabama\": \"AL\", \"Alaska\": \"AK\", \"Arizona\": \"AZ\", \"Arkansas\": \"AR\", \"California\": \"CA\",\n",
    "    \"Colorado\": \"CO\", \"Connecticut\": \"CT\", \"Delaware\": \"DE\", \"Florida\": \"FL\", \"Georgia\": \"GA\",\n",
    "    \"Hawaii\": \"HI\", \"Idaho\": \"ID\", \"Illinois\": \"IL\", \"Indiana\": \"IN\", \"Iowa\": \"IA\",\n",
    "    \"Kansas\": \"KS\", \"Kentucky\": \"KY\", \"Louisiana\": \"LA\", \"Maine\": \"ME\", \"Maryland\": \"MD\",\n",
    "    \"Massachusetts\": \"MA\", \"Michigan\": \"MI\", \"Minnesota\": \"MN\", \"Mississippi\": \"MS\", \"Missouri\": \"MO\",\n",
    "    \"Montana\": \"MT\", \"Nebraska\": \"NE\", \"Nevada\": \"NV\", \"New Hampshire\": \"NH\", \"New Jersey\": \"NJ\",\n",
    "    \"New Mexico\": \"NM\", \"New York\": \"NY\", \"North Carolina\": \"NC\", \"North Dakota\": \"ND\", \"Ohio\": \"OH\",\n",
    "    \"Oklahoma\": \"OK\", \"Oregon\": \"OR\", \"Pennsylvania\": \"PA\", \"Rhode Island\": \"RI\", \"South Carolina\": \"SC\",\n",
    "    \"South Dakota\": \"SD\", \"Tennessee\": \"TN\", \"Texas\": \"TX\", \"Utah\": \"UT\", \"Vermont\": \"VT\",\n",
    "    \"Virginia\": \"VA\", \"Washington\": \"WA\", \"West Virginia\": \"WV\", \"Wisconsin\": \"WI\", \"Wyoming\": \"WY\",\n",
    "}\n",
    "\n",
    "melted_df['state'] = melted_df['state'].map(us_state_to_abbrev)\n",
    "gdp_by_state = melted_df.rename(columns = {'amount': 'GDP'})\n",
    "gdp_by_state #naming to something we will remember\n",
    "gdp_by_state['year'] = gdp_by_state['year'].astype(int) # change to integers\n",
    "gdp_by_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merged Data Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>year</th>\n",
       "      <th>disasters</th>\n",
       "      <th>funding</th>\n",
       "      <th>party</th>\n",
       "      <th>GDP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AL</td>\n",
       "      <td>2019</td>\n",
       "      <td>36</td>\n",
       "      <td>5728503</td>\n",
       "      <td>REPUBLICAN</td>\n",
       "      <td>234526.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AL</td>\n",
       "      <td>2020</td>\n",
       "      <td>257</td>\n",
       "      <td>5810021</td>\n",
       "      <td>REPUBLICAN</td>\n",
       "      <td>235118.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AL</td>\n",
       "      <td>2021</td>\n",
       "      <td>30</td>\n",
       "      <td>7446681</td>\n",
       "      <td>REPUBLICAN</td>\n",
       "      <td>257986.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AL</td>\n",
       "      <td>2022</td>\n",
       "      <td>2</td>\n",
       "      <td>6681181</td>\n",
       "      <td>REPUBLICAN</td>\n",
       "      <td>281569.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AK</td>\n",
       "      <td>2019</td>\n",
       "      <td>9</td>\n",
       "      <td>3093229</td>\n",
       "      <td>REPUBLICAN</td>\n",
       "      <td>54469.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>WI</td>\n",
       "      <td>2022</td>\n",
       "      <td>0</td>\n",
       "      <td>7311711</td>\n",
       "      <td>REPUBLICAN</td>\n",
       "      <td>396209.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>WY</td>\n",
       "      <td>2019</td>\n",
       "      <td>0</td>\n",
       "      <td>2991828</td>\n",
       "      <td>REPUBLICAN</td>\n",
       "      <td>39971.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>WY</td>\n",
       "      <td>2020</td>\n",
       "      <td>51</td>\n",
       "      <td>3033266</td>\n",
       "      <td>REPUBLICAN</td>\n",
       "      <td>36675.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>WY</td>\n",
       "      <td>2021</td>\n",
       "      <td>0</td>\n",
       "      <td>3889834</td>\n",
       "      <td>REPUBLICAN</td>\n",
       "      <td>42176.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>WY</td>\n",
       "      <td>2022</td>\n",
       "      <td>0</td>\n",
       "      <td>3455841</td>\n",
       "      <td>REPUBLICAN</td>\n",
       "      <td>49080.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    state  year  disasters  funding       party       GDP\n",
       "0      AL  2019         36  5728503  REPUBLICAN  234526.4\n",
       "1      AL  2020        257  5810021  REPUBLICAN  235118.3\n",
       "2      AL  2021         30  7446681  REPUBLICAN  257986.5\n",
       "3      AL  2022          2  6681181  REPUBLICAN  281569.0\n",
       "4      AK  2019          9  3093229  REPUBLICAN   54469.9\n",
       "..    ...   ...        ...      ...         ...       ...\n",
       "195    WI  2022          0  7311711  REPUBLICAN  396209.3\n",
       "196    WY  2019          0  2991828  REPUBLICAN   39971.4\n",
       "197    WY  2020         51  3033266  REPUBLICAN   36675.5\n",
       "198    WY  2021          0  3889834  REPUBLICAN   42176.2\n",
       "199    WY  2022          0  3455841  REPUBLICAN   49080.6\n",
       "\n",
       "[200 rows x 6 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the data sets we have now are EMPG, disasters, state_political_leaning, & gdp_by_state \n",
    "#we have individually pre procesesed every data frame so that merging will be a smooth process\n",
    "pd.set_option('display.max_rows', 10)\n",
    "master_df = disasters.merge(EMPG)\n",
    "master_df = master_df.merge(state_political_leaning)\n",
    "master_df = master_df.merge(gdp_by_state)\n",
    "master_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Questions That Need Answering\n",
    "- Question 1: Is there a correlation between the number of disasters and the amount of funding allocated?\n",
    "    - Graph: A line or bar chart showing the number of disasters per state each year. This would visually illustrate trends and differences between states over the years.\n",
    "- Question 2: Does the political party in each state affect disaster funding (table)\n",
    "    - Table: A summary table showing average disaster funding by party and by state.\n",
    "    - Graph: Box plots or bar charts comparing disaster funding in Republican vs. Democrat states.\n",
    "- Question 3:How has the GDP of each state changed over the years, and is there any relationship with disaster occurrences or funding?\n",
    "    - Graph: Line charts showing the GDP trend for each state across the years.\n",
    "    - Graph: A scatter plot or a series of scatter plots showing GDP against number of disasters or funding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Section 1 - Correlation between Num. of disasters and Funding Allocated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ethics & Privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Thoughtful discussion of ethical concerns included\n",
    "- Ethical concerns consider the whole data science process (question asked, data collected, data being used, the bias in data, analysis, post-analysis, etc.)\n",
    "- How your group handled bias/ethical concerns clearly described\n",
    "\n",
    "Acknowledge and address any ethics & privacy related issues of your question(s), proposed dataset(s), and/or analyses. Use the information provided in lecture to guide your group discussion and thinking. If you need further guidance, check out [Deon's Ethics Checklist](http://deon.drivendata.org/#data-science-ethics-checklist). In particular:\n",
    "\n",
    "- Are there any biases/privacy/terms of use issues with the data you propsed?\n",
    "- Are there potential biases in your dataset(s), in terms of who it composes, and how it was collected, that may be problematic in terms of it allowing for equitable analysis? (For example, does your data exclude particular populations, or is it likely to reflect particular human biases in a way that could be a problem?)\n",
    "- How will you set out to detect these specific biases before, during, and after/when communicating your analysis?\n",
    "- Are there any other issues related to your topic area, data, and/or analyses that are potentially problematic in terms of data privacy and equitable impact?\n",
    "- How will you handle issues you identified?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team Expectations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Read over the [COGS108 Team Policies](https://github.com/COGS108/Projects/blob/master/COGS108_TeamPolicies.md) individually. Then, include your group’s expectations of one another for successful completion of your COGS108 project below. Discuss and agree on what all of your expectations are. Discuss how your team will communicate throughout the quarter and consider how you will communicate respectfully should conflicts arise. By including each member’s name above and by adding their name to the submission, you are indicating that you have read the COGS108 Team Policies, accept your team’s expectations below, and have every intention to fulfill them. These expectations are for your team’s use and benefit — they won’t be graded for their details.\n",
    "\n",
    "* *Team Expectation 1*\n",
    "* *Team Expectation 2*\n",
    "* *Team Expecation 3*\n",
    "* ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Timeline Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify your team's specific project timeline. An example timeline has been provided. Changes the dates, times, names, and details to fit your group's plan.\n",
    "\n",
    "If you think you will need any special resources or training outside what we have covered in COGS 108 to solve your problem, then your proposal should state these clearly. For example, if you have selected a problem that involves implementing multiple neural networks, please state this so we can make sure you know what you’re doing and so we can point you to resources you will need to implement your project. Note that you are not required to use outside methods.\n",
    "\n",
    "\n",
    "\n",
    "| Meeting Date  | Meeting Time| Completed Before Meeting  | Discuss at Meeting |\n",
    "|---|---|---|---|\n",
    "| 1/20  |  1 PM | Read & Think about COGS 108 expectations; brainstorm topics/questions  | Determine best form of communication; Discuss and decide on final project topic; discuss hypothesis; begin background research | \n",
    "| 1/26  |  10 AM |  Do background research on topic | Discuss ideal dataset(s) and ethics; draft project proposal | \n",
    "| 2/1  | 10 AM  | Edit, finalize, and submit proposal; Search for datasets  | Discuss Wrangling and possible analytical approaches; Assign group members to lead each specific part   |\n",
    "| 2/14  | 6 PM  | Import & Wrangle Data (Ant Man); EDA (Hulk) | Review/Edit wrangling/EDA; Discuss Analysis Plan   |\n",
    "| 2/23  | 12 PM  | Finalize wrangling/EDA; Begin Analysis (Iron Man; Thor) | Discuss/edit Analysis; Complete project check-in |\n",
    "| 3/13  | 12 PM  | Complete analysis; Draft results/conclusion/discussion (Wasp)| Discuss/edit full project |\n",
    "| 3/20  | Before 11:59 PM  | NA | Turn in Final Project & Group Project Surveys |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
