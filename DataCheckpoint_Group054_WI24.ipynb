{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 108 - Data Checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Names\n",
    "\n",
    "- Ivan Chen \n",
    "- Leo Fleury\n",
    "- Daniel Yoon   \n",
    "- Fei He\n",
    "- HaoTing Huang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Research Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the association between the amount of federal money a state receives for disaster relief and the factors, state GDP , number of disasters, and political leaning per year from 2017 to 2022?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background and Prior Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The United States was born out of the colonies' desire to free from the tyranny of a government holding complete control over their commerce and rights. This wariness of a centralized governmental structure influences many aspects of how the government runs today, such as the separation of powers as labeled within the United States Constitution. The states can be considered, to an extent, nations within a nation. A study published in 2023 by smartasset<a name=\"cite_ref-1\"></a>[<sup>1</sup>](#cite_note-1) displays one aspect of this relationship - the depth to which states receive their funding from the federal government. But after decades of peace and prosperity as a singular united nation on the world stage - how many maintain this level of self-sufficiency in disasters?\n",
    "\n",
    "Another source we looked at was a data science project done by Money Geek that looked at which states were most reliant on federal aid. This project is relevant to ours because federal aid reduces the burden on a states budget and how much they can allocate towards disaster relief <a name=\"cite_ref-2\"></a>[<sup>2</sup>](#cite_note-2). To compute this, the team at Money Geek did not just look at total federal aid, but looked at federal funding as a percentage of state revenue and return on tax dollars which was a statistic showing how much the state got back for every dollar that they gave the government. What we learned from the metrics used (such as aid as a percentage of state revenue and return on tax dollars) is that often a data set will require a lot of cleaning and development of our own metrics before we can get the answer to our question. Our question being the relation between GDP and a state's amount spent on disaster relief. From the Money Geek project, we also saw how others incorporate graphs into their findings. Money geek did a very good job about making the main findings visible in the titles of their graphs and throughout their paragraphs. For example, one of the main findings from the data set was that states that get the most in federal aid are often republican states. Then, they created a illustrative bar chart to display this. \n",
    "\n",
    "Lastly, another project we found relevant from economy.com looking at how natural disasters affect national GDP, which we also found relevant to our project as it relates to natural disasters and uses GDP as a metric. However, our project takes a different angle by using GDP as a measure of a states self sufficiency and seeing how that correlates to how much disaster relief aid that state gets. Some relevant take-aways from the source were that natural disasters only have a minor impact on national GDP but can be very impactful for local GDP. For example, from economy.com calculations, real GDP growth for New Orleans fell 20% at an annual rate in the third quarter of 2005 after Katrina <a name=\"cite_ref-3\"></a>[<sup>3</sup>](#cite_note-3). \n",
    "\n",
    "1. <a name=\\\"cite_note-1\\\"></a> [^](#cite_ref-1) Jaclyn, D. (14 Apr. 2023)  Where Your Tax Dollars Go: States Most Dependent on the Federal Government â€“ 2023 Study *smartasset* https://smartasset.com/data-studies/states-most-dependent-federal-government-2023 \n",
    "2. <a name=\\\"cite_note-2\\\"></a> [^](#cite_ref-2) MoneyGeek. (n.d.). States Most Reliant on the Federal Government., from https://www.moneygeek.com/living/states-most-reliant-federal-government/\n",
    "3. <a name=\\\"cite_note-3\\\"></a> [^](#cite_ref-3) Moody's Analytics. (n.d.). How Natural Disasters Affect US GDP. Economy.com., from https://www.economy.com/economicview/analysis/296804/How-Natural-Disasters-Affect-US-GDP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We predict that in the United States in 2022, states with lower Gross Domestic Product (GDP) and historical Republican inclinations will be associated with an increase in federal disaster relief funding (as a percentage of the state's GDP). Conversely, states with higher GDP and historical Democratic ties will receive a lower percentage of their GDP in federal disaster relief funding. This study aims to analyze data over the past two decades to investigate these relationships, employing statistical analysis methods to understand the impact of economic status and political affiliation on disaster relief funding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data overview\n",
    "\n",
    "For each dataset include the following information\n",
    "- Dataset #1\n",
    "  - Dataset Name: Gross Domestic Product (GDP) by state\n",
    "  - Link to the dataset: https://usafacts.org/metrics/gross-domestic-product-gdp-by-state/?adjustment=None&timeGranularity=Yearly\n",
    "  - Number of observations: 45\n",
    "  - Number of variables: 51\n",
    "- Dataset #2 \n",
    "  - Dataset Name:\n",
    "  - Link to the dataset: https://www.bea.gov/data/gdp/gdp-state\n",
    "  - Number of observations:\n",
    "  - Number of variables:\n",
    "- Dataset #3\n",
    "  - Dataset Name: Emergency Management Performance Grants\n",
    "  - Link to dataset: https://www.fema.gov/openfema-data-page/emergency-management-performance-grants-v2\n",
    "  - Number of observations: 19615\n",
    "  - Number of variables: 9\n",
    "- Dataset #4\n",
    "  - Dataset Name: Public Assistance Funded Projects Detail\n",
    "  - Link to dataset: https://www.fema.gov/openfema-data-page/public-assistance-funded-projects-details-v1\n",
    "  - Number of observations: 805,572\n",
    "  - Number of variables: 22\n",
    "\n",
    "\n",
    "For our first dataset, GDP by state, is a dataset that gives us each states, GDP by year. The dataset includes data from 1977 - 2022, with the GDP of each state per year. The states are organized by alphabetical order and the year from 2022 down to 1977. As for data, majority of it are integers, which simplifies it a little. As for cleaning the dataset, we want to extract data from 2017 to 2022 only, which means we need to filter more than half the dataset.\n",
    "\n",
    "The second dataset by BEA, it is a dataset that provides the GDP by each state, seperated by region from most to least. This dataset includes each states GDP by quarter and takes inflation into account (2017 Dollar value). This dataset has many tables with valuable information, but we are focused on Tables 1, 3, and 5. Table 2 includes data about the Personal Income per state in the same format as Table 1. A few important varaibles in this dataset would include States, Regions, Quarters, and Total. These are the main variables that will help us analyze the data. Since the data is already well organized, the only things we would need to do is find missing data, if there is any, and understand why it may be missing. \n",
    "\n",
    "Our third dataset, Emergency Managment Performance Grants, is a detailed dataset of emergency funding each state as received. This dataset inlcudes every agency that has provided a specific state emergency funding. The data variables includes states, id, agency name, closing and opening date, and more. We are mainly looking for state, amount and reporting period (2017-2022), so we can focus on extracting those variables out. With the large amount of agency's in each state, it would be best to combine it all under the state, where we have the total number of funding per state. \n",
    "\n",
    "Our last dataset, Public Assistance Funded Projects Detail, is another very detailed dataset that has information about emergency funding. To be more exact, it has information about what kind of natural disasters, which county and it's county code, project amount, federal share obligated, total obligated, and more. For this project, knowing what specific natural disaster and how much a state got because of that isn't our main goal, so we would have to sort it by year, maintaining our goal of finding data from 2017-2022.\n",
    "\n",
    "\n",
    "With our datasets, it would be useful to look at them and understand if a state with a higher GDP gets more emergency funding overall. We want to see the relationships between the two and with the information we have, it would help prove our research question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset #1 (Gross Domestic Product (GDP) by state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leofl\\AppData\\Local\\Temp\\ipykernel_23152\\3617419432.py:42: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  df_grouped = df.groupby(by = ['state', 'reportingPeriod']).sum()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>year</th>\n",
       "      <th>funding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>2019</td>\n",
       "      <td>5728503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>2020</td>\n",
       "      <td>5810021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>2021</td>\n",
       "      <td>7446681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>2022</td>\n",
       "      <td>6681181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>2019</td>\n",
       "      <td>3093229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>2022</td>\n",
       "      <td>7311711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>2019</td>\n",
       "      <td>2991828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>2020</td>\n",
       "      <td>3033266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>2021</td>\n",
       "      <td>3889834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>2022</td>\n",
       "      <td>3455841</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         state  year  funding\n",
       "0      Alabama  2019  5728503\n",
       "1      Alabama  2020  5810021\n",
       "2      Alabama  2021  7446681\n",
       "3      Alabama  2022  6681181\n",
       "4       Alaska  2019  3093229\n",
       "..         ...   ...      ...\n",
       "195  Wisconsin  2022  7311711\n",
       "196    Wyoming  2019  2991828\n",
       "197    Wyoming  2020  3033266\n",
       "198    Wyoming  2021  3889834\n",
       "199    Wyoming  2022  3455841\n",
       "\n",
       "[200 rows x 3 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "url = 'Data/EmergencyManagementPerformanceGrants.csv'\n",
    "df = pd.read_csv(url)\n",
    "df['state'].unique()\n",
    "df_not_state = df['state'].str.contains('Puerto Rico|American Samoa|District of Columbia|Northern Mariana Islands|Guam|Virgin Islands')\n",
    "df = df[~df_not_state] #filter to only include US states\n",
    "df['state'].unique().size #check to see that our state column only has 50 values\n",
    "\n",
    "def standardize_reportingPeriod(string):\n",
    "    \n",
    "    string = string.lower().strip()\n",
    "    \n",
    "    if '2014' in string:\n",
    "        output = 2014\n",
    "    elif '2015' in string:\n",
    "        output = 2015\n",
    "    elif '2016' in string:\n",
    "        output = 2016\n",
    "    elif '2017' in string:\n",
    "        output = 2017\n",
    "    elif '2018' in string:\n",
    "        output = 2018\n",
    "    elif '2019' in string:\n",
    "        output = 2019\n",
    "    elif '2020' in string:\n",
    "        output = 2020\n",
    "    elif '2021' in string:\n",
    "        output = 2021\n",
    "    elif '2022' in string:\n",
    "        output = 2022\n",
    "    # Otherwise, if uncaught - keep as is\n",
    "    else:\n",
    "        output = string\n",
    "    \n",
    "    return output\n",
    "\n",
    "df['reportingPeriod'] = df['reportingPeriod'].apply(standardize_reportingPeriod)\n",
    "df\n",
    "df = df.query('reportingPeriod >= 2019') #filter so lowest year is 2017 to match other data\n",
    "\n",
    "df_grouped = df.groupby(by = ['state', 'reportingPeriod']).sum()\n",
    "df_grouped = df_grouped.reset_index()\n",
    "df_grouped = df_grouped.rename(columns = {'reportingPeriod': 'year', 'fundingAmount' : 'funding'})\n",
    "pd.set_option('display.max_rows', 10)\n",
    "df_grouped['funding'] = df_grouped['funding'].astype(int)\n",
    "df_grouped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset #2 Disaster Declarations by State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>year</th>\n",
       "      <th>num_disasters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AL</td>\n",
       "      <td>2019</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AL</td>\n",
       "      <td>2020</td>\n",
       "      <td>257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AL</td>\n",
       "      <td>2021</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AL</td>\n",
       "      <td>2022</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AK</td>\n",
       "      <td>2019</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>WI</td>\n",
       "      <td>2022</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>WY</td>\n",
       "      <td>2019</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>WY</td>\n",
       "      <td>2020</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>WY</td>\n",
       "      <td>2021</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>WY</td>\n",
       "      <td>2022</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    state  year  num_disasters\n",
       "0      AL  2019             36\n",
       "1      AL  2020            257\n",
       "2      AL  2021             30\n",
       "3      AL  2022              2\n",
       "4      AK  2019              9\n",
       "..    ...   ...            ...\n",
       "195    WI  2022              0\n",
       "196    WY  2019              0\n",
       "197    WY  2020             51\n",
       "198    WY  2021              0\n",
       "199    WY  2022              0\n",
       "\n",
       "[200 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url2 = 'Data/DisasterDeclarationsSummaries.csv'\n",
    "df2= pd.read_csv(url2)\n",
    "df2 = df2.query('2023 > fyDeclared >= 2019 ') # make sure to include equals so 2017 included\n",
    "df2.sort_values(by = 'fyDeclared', ascending = True) # set to true so make sure have correct info\n",
    "df2 = df2.groupby(by = ['state', 'fyDeclared']).size().reset_index(name= 'num_disasters') # use size for num of disasters instead of sum & give column name\n",
    "df2 = df2.rename(columns={'fyDeclared': 'year'})\n",
    "valid_states = ['AL', 'AK', 'AZ', 'AR', 'CA', 'CO', 'CT', 'DE', 'FL', 'GA', \n",
    "                'HI', 'ID', 'IL', 'IN', 'IA', 'KS', 'KY', 'LA', 'ME', 'MD', \n",
    "                'MA', 'MI', 'MN', 'MS', 'MO', 'MT', 'NE', 'NV', 'NH', 'NJ', \n",
    "                'NM', 'NY', 'NC', 'ND', 'OH', 'OK', 'OR', 'PA', 'RI', 'SC', \n",
    "                'SD', 'TN', 'TX', 'UT', 'VT', 'VA', 'WA', 'WV', 'WI', 'WY']\n",
    "\n",
    "# Filter the DataFrame to only include rows where the state code is in the list of valid states\n",
    "df2 = df2[df2['state'].isin(valid_states)]\n",
    "df2\n",
    "\n",
    "# states didnt have disasters every year so we need to create columns with 0 for years no disasters were declared\n",
    "import itertools\n",
    "\n",
    "years = [2019, 2020, 2021, 2022]\n",
    "combinations = list(itertools.product(valid_states, years)) # Use itertools.product to get all combinations of states and years -- this works like a double sum where the valid states is fixed and its looking at all the states to match\n",
    "combinations\n",
    "df2_combinations = pd.DataFrame(combinations, columns=['state', 'year'])\n",
    "df2_combinations\n",
    "df2_merged = pd.merge(df2_combinations, df2, on = ['state', 'year'], how = 'left')# how on left so that df2_combinations has all rows saved and df2 added -- state and year pairs will get na values\n",
    "df2_merged['num_disasters'].fillna(0, inplace= True) #in place so a new data frame is not created and old one is kept\n",
    "df2_merged['num_disasters'] = df2_merged['num_disasters'].astype(int) # astype converts to a integer\n",
    "df2_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset #3 State Historical Political Leaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>year</th>\n",
       "      <th>party</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AL</td>\n",
       "      <td>2019</td>\n",
       "      <td>REPUBLICAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AL</td>\n",
       "      <td>2020</td>\n",
       "      <td>REPUBLICAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AL</td>\n",
       "      <td>2021</td>\n",
       "      <td>REPUBLICAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AL</td>\n",
       "      <td>2022</td>\n",
       "      <td>REPUBLICAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AK</td>\n",
       "      <td>2019</td>\n",
       "      <td>REPUBLICAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>WI</td>\n",
       "      <td>2022</td>\n",
       "      <td>REPUBLICAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>WY</td>\n",
       "      <td>2019</td>\n",
       "      <td>REPUBLICAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>WY</td>\n",
       "      <td>2020</td>\n",
       "      <td>REPUBLICAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>WY</td>\n",
       "      <td>2021</td>\n",
       "      <td>REPUBLICAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>WY</td>\n",
       "      <td>2022</td>\n",
       "      <td>REPUBLICAN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>204 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    state  year       party\n",
       "0      AL  2019  REPUBLICAN\n",
       "1      AL  2020  REPUBLICAN\n",
       "2      AL  2021  REPUBLICAN\n",
       "3      AL  2022  REPUBLICAN\n",
       "4      AK  2019  REPUBLICAN\n",
       "..    ...   ...         ...\n",
       "199    WI  2022  REPUBLICAN\n",
       "200    WY  2019  REPUBLICAN\n",
       "201    WY  2020  REPUBLICAN\n",
       "202    WY  2021  REPUBLICAN\n",
       "203    WY  2022  REPUBLICAN\n",
       "\n",
       "[204 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url3 = 'Data/1976-2022-house.csv'\n",
    "election_data= pd.read_csv(url3)\n",
    "pd.set_option('display.max_rows', 10)\n",
    "\n",
    "elections_post_2017 = election_data[election_data['year'] > 2019]\n",
    "relevant_elections = elections_post_2017[elections_post_2017['party'].isin(['DEMOCRAT', 'REPUBLICAN'])]\n",
    "grouped_elections = relevant_elections.groupby(['state', 'year', 'party'])['candidatevotes'].sum().reset_index()\n",
    "winning_party = grouped_elections.sort_values('candidatevotes', ascending=False).drop_duplicates(['state', 'year'])\n",
    "winning_party = winning_party.sort_values(by = 'state')\n",
    "winning_party = winning_party.drop(columns= 'candidatevotes')\n",
    "\n",
    "\n",
    "#df.reindex -- confrom DF to a new index w. optional filling -- places NA in locastions having no value in teh previous index\n",
    "# we reindex the winning_party data frame to do this\n",
    "# we use pd.MultiIndex.from_product instead of iterools.prodcut(state, year) bcs it returns a list instead of a multiindex\n",
    "winning_party_indexed = winning_party.set_index(['state', 'year'])\n",
    "state = winning_party_indexed.index.levels[0]\n",
    "year = [2019,2020,2021,2022]\n",
    "multi_index = pd.MultiIndex.from_product([state, year])\n",
    "winning_party_indexed = winning_party_indexed.reindex(multi_index)\n",
    "winning_party_indexed_filled = winning_party_indexed.groupby(level=0).fillna(method='ffill').fillna(method='bfill').reset_index()\n",
    "winning_party_indexed_filled = winning_party_indexed_filled.rename(columns = {'level_1' : 'year'})\n",
    "\n",
    "#the rest of our data tables use state postal codes instead of the full names\n",
    "#using a dictionary I found on GitHub we can map these states to their postal codes\n",
    "us_state_to_abbrev = {\n",
    "    \"Alabama\": \"AL\", \"Alaska\": \"AK\", \"Arizona\": \"AZ\", \"Arkansas\": \"AR\", \"California\": \"CA\",\n",
    "    \"Colorado\": \"CO\", \"Connecticut\": \"CT\", \"Delaware\": \"DE\", \"Florida\": \"FL\", \"Georgia\": \"GA\",\n",
    "    \"Hawaii\": \"HI\", \"Idaho\": \"ID\", \"Illinois\": \"IL\", \"Indiana\": \"IN\", \"Iowa\": \"IA\",\n",
    "    \"Kansas\": \"KS\", \"Kentucky\": \"KY\", \"Louisiana\": \"LA\", \"Maine\": \"ME\", \"Maryland\": \"MD\",\n",
    "    \"Massachusetts\": \"MA\", \"Michigan\": \"MI\", \"Minnesota\": \"MN\", \"Mississippi\": \"MS\", \"Missouri\": \"MO\",\n",
    "    \"Montana\": \"MT\", \"Nebraska\": \"NE\", \"Nevada\": \"NV\", \"New Hampshire\": \"NH\", \"New Jersey\": \"NJ\",\n",
    "    \"New Mexico\": \"NM\", \"New York\": \"NY\", \"North Carolina\": \"NC\", \"North Dakota\": \"ND\", \"Ohio\": \"OH\",\n",
    "    \"Oklahoma\": \"OK\", \"Oregon\": \"OR\", \"Pennsylvania\": \"PA\", \"Rhode Island\": \"RI\", \"South Carolina\": \"SC\",\n",
    "    \"South Dakota\": \"SD\", \"Tennessee\": \"TN\", \"Texas\": \"TX\", \"Utah\": \"UT\", \"Vermont\": \"VT\",\n",
    "    \"Virginia\": \"VA\", \"Washington\": \"WA\", \"West Virginia\": \"WV\", \"Wisconsin\": \"WI\", \"Wyoming\": \"WY\",\n",
    "}\n",
    "\n",
    "winning_party_indexed_filled['state'] = winning_party_indexed_filled['state'].str.lower().str.capitalize().map(us_state_to_abbrev)\n",
    "winning_party_indexed_filled\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset #4 GDP by State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log onto the BEA website (Bureau of Economic Analysis), the official site for government data.\n",
    "# Navigate to the \"Data\" section, select \"GDP,\" and then choose \"GDP by State.\"\n",
    "# Go to \"Interactive Data\" and select \"Interactive Tables: GDP by State.\"\n",
    "# Choose \"ANNUAL GROSS DOMESTIC PRODUCT (GDP) BY STATE,\" then \"SAGDP2 GDP in current dollars.\"\n",
    "# Select the United States, and view all statistics in the table.\n",
    "# In the resulting table, select the first row's line code where the description is \"all industry total.\"\n",
    "# The resulting table displays the GDP by state in millions of current dollars, with data collected from 2017 to 2022.\n",
    "\n",
    "url4 =  \"Data/GDP by state (2017-2022).csv\"\n",
    "\n",
    "df4 = pd.read_csv(url4, skiprows = 3) #skip first 3 rows because they are a description\n",
    "df4 = df4.drop(columns = ['GeoFips', '2017', '2018'])\n",
    "df4 = df4.rename(columns= {'GeoName': 'state'})\n",
    "df4_bad_GeoName = df4['state'].str.contains('District of Columbia|New England|nited States *|Mideast|Great Lakes|Plains|Southeast|Southwest|nan|Rocky Mountain|Far West').fillna(False) #dealing with NA values\n",
    "df4 = df4[~ df4_bad_GeoName] #this removes all the regions and territories we don't care about \n",
    "indexes_to_drop = df4.iloc[-4:].index #get the last 4 rows index using iloc\n",
    "df4 = df4.drop(indexes_to_drop)\n",
    "melted_df = pd.melt(df4, id_vars=['state'], value_vars=['2019', '2020', '2021', '2022'], var_name='year', value_name='amount')\n",
    "melted_df = melted_df.sort_values('state')\n",
    "melted_df\n",
    "\n",
    "#using the same code I used on the state leaning dat set we change the years to their postal codes\n",
    "\n",
    "us_state_to_abbrev = {\n",
    "    \"Alabama\": \"AL\", \"Alaska\": \"AK\", \"Arizona\": \"AZ\", \"Arkansas\": \"AR\", \"California\": \"CA\",\n",
    "    \"Colorado\": \"CO\", \"Connecticut\": \"CT\", \"Delaware\": \"DE\", \"Florida\": \"FL\", \"Georgia\": \"GA\",\n",
    "    \"Hawaii\": \"HI\", \"Idaho\": \"ID\", \"Illinois\": \"IL\", \"Indiana\": \"IN\", \"Iowa\": \"IA\",\n",
    "    \"Kansas\": \"KS\", \"Kentucky\": \"KY\", \"Louisiana\": \"LA\", \"Maine\": \"ME\", \"Maryland\": \"MD\",\n",
    "    \"Massachusetts\": \"MA\", \"Michigan\": \"MI\", \"Minnesota\": \"MN\", \"Mississippi\": \"MS\", \"Missouri\": \"MO\",\n",
    "    \"Montana\": \"MT\", \"Nebraska\": \"NE\", \"Nevada\": \"NV\", \"New Hampshire\": \"NH\", \"New Jersey\": \"NJ\",\n",
    "    \"New Mexico\": \"NM\", \"New York\": \"NY\", \"North Carolina\": \"NC\", \"North Dakota\": \"ND\", \"Ohio\": \"OH\",\n",
    "    \"Oklahoma\": \"OK\", \"Oregon\": \"OR\", \"Pennsylvania\": \"PA\", \"Rhode Island\": \"RI\", \"South Carolina\": \"SC\",\n",
    "    \"South Dakota\": \"SD\", \"Tennessee\": \"TN\", \"Texas\": \"TX\", \"Utah\": \"UT\", \"Vermont\": \"VT\",\n",
    "    \"Virginia\": \"VA\", \"Washington\": \"WA\", \"West Virginia\": \"WV\", \"Wisconsin\": \"WI\", \"Wyoming\": \"WY\",\n",
    "}\n",
    "melted_df['state'] = melted_df['state'].str.lower().str.capitalize().map(us_state_to_abbrev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ethics & Privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data is sourced from governmental agencies and nonprofit organizations such as USA Facts, FEMA, and BEA.gov. These sources aim to provide a strictly non-partisan outlook on the actions of the federal government in an effort to promote a pillar of government so necessary to any government's foundation - transparency. These sources do not contain any private data, as any data determined to be accessible to the public by the Freedom of Information act forgoes data which would be deemed a breach of privacy. Our research does not aim to harm any particular population within a county or state, as it is focused on compiling and analyzing the financial aspect of the relationship between state and federal governments. Moreover, decisions on federal funding are guided by uniform, pre-established standards, and commitments, all found within the constitution of the United States. Our compilation of statistical information lacks sufficient means to overturn the nature of this centuries old relation. Electoral data analyzed is on a strictly state-level basis, meaning that we do not utilize a voter's personal information. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team Expectations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* *Be Communicative* - Communicate any difficulties ahead of time! If assistance is needed, or maybe if a team member is unable to do/finish what they need to do, communicating it ahead of time will allow others to help expedite the process.\n",
    "\n",
    "* *Contribute Fairly* - Uphold the responsibilities assigned or taken up by each individual group member, but also keep in mind to make key decisions as a group. \n",
    "\n",
    "* *Communication Guideline* - Communicate primarily through Discord and attend scheduled weekly/bi-weekly calls. Most, if not all calls will be virtual, but be present and be involved in the project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Timeline Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Meeting Date | Meeting Time | Completed Before Meeting      | Discuss at Meeting                                                                 |\n",
    "|--------------|--------------|-------------------------------|------------------------------------------------------------------------------------|\n",
    "| 2/4          | 6 PM         | Read Previous COGS 108 Projects | Discussed the strengths and weaknesses of two COGS 108 projects made by previous groups and noted things to keep and leave in our projects. |\n",
    "| 2/8          | 3 PM         | Research Question              | Discuss hypothesis, research question, project timeline proposal                   |\n",
    "| 2/11         | 6 PM         | Work on Project Proposal       | Discuss hypothesis, research question, project timeline proposal                   |\n",
    "| 2/19         | 7 PM         | Find Relevant Data             | Choose which data we found best fits our research purposes                         |\n",
    "| 2/22         | 8:30 PM      | Categorize Relevant Data       | Discuss what kind of further questions we want to ask within our research question |\n",
    "| 3/4          | 7 PM         | Work on individual categories  | Review and discuss progress                                                        |\n",
    "| 3/7          | 7 PM         | Work on individual categories  | Review and discuss progress                                                        |\n",
    "| 3/14         | 7 PM         | Work on individual categories  | Review and discuss progress                                                        |\n",
    "| 3/17         | 7 PM         | Work on individual categories  | Review and discuss progress                                                        |\n",
    "| 3/20         | Before 11:59\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
