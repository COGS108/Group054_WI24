{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 108 - Data Checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Names\n",
    "\n",
    "- Ivan Chen \n",
    "- Leo Fleury\n",
    "- Daniel Yoon   \n",
    "- Fei He\n",
    "- HaoTing Huang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Research Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the association between the amount of federal money a state receives for disaster relief and the factors, state GDP , number of disasters, and political leaning per year from 2017 to 2022?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background and Prior Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The United States was born out of the colonies' desire to free from the tyranny of a government holding complete control over their commerce and rights. This wariness of a centralized governmental structure influences many aspects of how the government runs today, such as the separation of powers as labeled within the United States Constitution. The states can be considered, to an extent, nations within a nation. A study published in 2023 by smartasset<a name=\"cite_ref-1\"></a>[<sup>1</sup>](#cite_note-1) displays one aspect of this relationship - the depth to which states receive their funding from the federal government. But after decades of peace and prosperity as a singular united nation on the world stage - how many maintain this level of self-sufficiency in disasters?\n",
    "\n",
    "Another source we looked at was a data science project done by Money Geek that looked at which states were most reliant on federal aid. This project is relevant to ours because federal aid reduces the burden on a states budget and how much they can allocate towards disaster relief <a name=\"cite_ref-2\"></a>[<sup>2</sup>](#cite_note-2). To compute this, the team at Money Geek did not just look at total federal aid, but looked at federal funding as a percentage of state revenue and return on tax dollars which was a statistic showing how much the state got back for every dollar that they gave the government. What we learned from the metrics used (such as aid as a percentage of state revenue and return on tax dollars) is that often a data set will require a lot of cleaning and development of our own metrics before we can get the answer to our question. Our question being the relation between GDP and a state's amount spent on disaster relief. From the Money Geek project, we also saw how others incorporate graphs into their findings. Money geek did a very good job about making the main findings visible in the titles of their graphs and throughout their paragraphs. For example, one of the main findings from the data set was that states that get the most in federal aid are often republican states. Then, they created a illustrative bar chart to display this. \n",
    "\n",
    "Lastly, another project we found relevant from economy.com looking at how natural disasters affect national GDP, which we also found relevant to our project as it relates to natural disasters and uses GDP as a metric. However, our project takes a different angle by using GDP as a measure of a states self sufficiency and seeing how that correlates to how much disaster relief aid that state gets. Some relevant take-aways from the source were that natural disasters only have a minor impact on national GDP but can be very impactful for local GDP. For example, from economy.com calculations, real GDP growth for New Orleans fell 20% at an annual rate in the third quarter of 2005 after Katrina <a name=\"cite_ref-3\"></a>[<sup>3</sup>](#cite_note-3). \n",
    "\n",
    "1. <a name=\\\"cite_note-1\\\"></a> [^](#cite_ref-1) Jaclyn, D. (14 Apr. 2023)  Where Your Tax Dollars Go: States Most Dependent on the Federal Government – 2023 Study *smartasset* https://smartasset.com/data-studies/states-most-dependent-federal-government-2023 \n",
    "2. <a name=\\\"cite_note-2\\\"></a> [^](#cite_ref-2) MoneyGeek. (n.d.). States Most Reliant on the Federal Government., from https://www.moneygeek.com/living/states-most-reliant-federal-government/\n",
    "3. <a name=\\\"cite_note-3\\\"></a> [^](#cite_ref-3) Moody's Analytics. (n.d.). How Natural Disasters Affect US GDP. Economy.com., from https://www.economy.com/economicview/analysis/296804/How-Natural-Disasters-Affect-US-GDP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We predict that in the United States in 2022, states with lower Gross Domestic Product (GDP) and historical Republican inclinations will be associated with an increase in federal disaster relief funding (as a percentage of the state's GDP). Conversely, states with higher GDP and historical Democratic ties will receive a lower percentage of their GDP in federal disaster relief funding. This study aims to analyze data over the past two decades to investigate these relationships, employing statistical analysis methods to understand the impact of economic status and political affiliation on disaster relief funding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data overview\n",
    "\n",
    "For each dataset include the following information\n",
    "- Dataset #1\n",
    "  - Dataset Name: Gross Domestic Product (GDP) by state\n",
    "  - Link to the dataset: https://usafacts.org/metrics/gross-domestic-product-gdp-by-state/?adjustment=None&timeGranularity=Yearly\n",
    "  - Number of observations: 45\n",
    "  - Number of variables: 51\n",
    "- Dataset #2 \n",
    "  - Dataset Name:\n",
    "  - Link to the dataset: https://www.bea.gov/data/gdp/gdp-state\n",
    "  - Number of observations:\n",
    "  - Number of variables:\n",
    "- Dataset #3\n",
    "  - Dataset Name: Emergency Management Performance Grants\n",
    "  - Link to dataset: https://www.fema.gov/openfema-data-page/emergency-management-performance-grants-v2\n",
    "  - Number of observations: 19615\n",
    "  - Number of variables: 9\n",
    "- Dataset #4\n",
    "  - Dataset Name: Public Assistance Funded Projects Detail\n",
    "  - Link to dataset: https://www.fema.gov/openfema-data-page/public-assistance-funded-projects-details-v1\n",
    "  - Number of observations: 805,572\n",
    "  - Number of variables: 22\n",
    "\n",
    "\n",
    "For our first dataset, GDP by state, is a dataset that gives us each states, GDP by year. The dataset includes data from 1977 - 2022, with the GDP of each state per year. The states are organized by alphabetical order and the year from 2022 down to 1977. As for data, majority of it are integers, which simplifies it a little. As for cleaning the dataset, we want to extract data from 2017 to 2022 only, which means we need to filter more than half the dataset.\n",
    "\n",
    "The second dataset by BEA, it is a dataset that provides the GDP by each state, seperated by region from most to least. This dataset includes each states GDP by quarter and takes inflation into account (2017 Dollar value). This dataset has many tables with valuable information, but we are focused on Tables 1, 3, and 5. Table 2 includes data about the Personal Income per state in the same format as Table 1. A few important varaibles in this dataset would include States, Regions, Quarters, and Total. These are the main variables that will help us analyze the data. Since the data is already well organized, the only things we would need to do is find missing data, if there is any, and understand why it may be missing. \n",
    "\n",
    "Our third dataset, Emergency Managment Performance Grants, is a detailed dataset of emergency funding each state as received. This dataset inlcudes every agency that has provided a specific state emergency funding. The data variables includes states, id, agency name, closing and opening date, and more. We are mainly looking for state, amount and reporting period (2017-2022), so we can focus on extracting those variables out. With the large amount of agency's in each state, it would be best to combine it all under the state, where we have the total number of funding per state. \n",
    "\n",
    "Our last dataset, Public Assistance Funded Projects Detail, is another very detailed dataset that has information about emergency funding. To be more exact, it has information about what kind of natural disasters, which county and it's county code, project amount, federal share obligated, total obligated, and more. For this project, knowing what specific natural disaster and how much a state got because of that isn't our main goal, so we would have to sort it by year, maintaining our goal of finding data from 2017-2022.\n",
    "\n",
    "\n",
    "With our datasets, it would be useful to look at them and understand if a state with a higher GDP gets more emergency funding overall. We want to see the relationships between the two and with the information we have, it would help prove our research question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset #1 (Gross Domestic Product (GDP) by state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leofl\\AppData\\Local\\Temp\\ipykernel_17888\\3592360326.py:41: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  df = df.groupby(by = ['state', 'reportingPeriod']).sum()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>year</th>\n",
       "      <th>fundingAmount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>2019</td>\n",
       "      <td>5728503.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>2020</td>\n",
       "      <td>5810021.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>2021</td>\n",
       "      <td>7446681.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>2022</td>\n",
       "      <td>6681181.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>2017</td>\n",
       "      <td>3101574.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>2017</td>\n",
       "      <td>3001110.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>2019</td>\n",
       "      <td>2991828.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>2020</td>\n",
       "      <td>3033266.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>2021</td>\n",
       "      <td>3889834.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>2022</td>\n",
       "      <td>3455841.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>272 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       state  year  fundingAmount\n",
       "0    Alabama  2019     5728503.00\n",
       "1    Alabama  2020     5810021.00\n",
       "2    Alabama  2021     7446681.00\n",
       "3    Alabama  2022     6681181.00\n",
       "4     Alaska  2017     3101574.00\n",
       "..       ...   ...            ...\n",
       "267  Wyoming  2017     3001110.91\n",
       "268  Wyoming  2019     2991828.00\n",
       "269  Wyoming  2020     3033266.50\n",
       "270  Wyoming  2021     3889834.00\n",
       "271  Wyoming  2022     3455841.00\n",
       "\n",
       "[272 rows x 3 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "url = 'Data/EmergencyManagementPerformanceGrants.csv'\n",
    "df = pd.read_csv(url)\n",
    "df['state'].unique()\n",
    "df_not_state = df['state'].str.contains('Puerto Rico|American Samoa|District of Columbia|Northern Mariana Islands|Guam|Virgin Islands')\n",
    "df = df[~df_not_state] #filter to only include US states\n",
    "df['state'].unique().size #check to see that our state column only has 50 values\n",
    "\n",
    "def standardize_reportingPeriod(string):\n",
    "    \n",
    "    string = string.lower().strip()\n",
    "    \n",
    "    if '2014' in string:\n",
    "        output = 2014\n",
    "    elif '2015' in string:\n",
    "        output = 2015\n",
    "    elif '2016' in string:\n",
    "        output = 2016\n",
    "    elif '2017' in string:\n",
    "        output = 2017\n",
    "    elif '2018' in string:\n",
    "        output = 2018\n",
    "    elif '2019' in string:\n",
    "        output = 2019\n",
    "    elif '2020' in string:\n",
    "        output = 2020\n",
    "    elif '2021' in string:\n",
    "        output = 2021\n",
    "    elif '2022' in string:\n",
    "        output = 2022\n",
    "    # Otherwise, if uncaught - keep as is\n",
    "    else:\n",
    "        output = string\n",
    "    \n",
    "    return output\n",
    "\n",
    "df['reportingPeriod'] = df['reportingPeriod'].apply(standardize_reportingPeriod)\n",
    "df = df.query('reportingPeriod >= 2017') #filter so lowest year is 2017 to match other data\n",
    "\n",
    "df = df.groupby(by = ['state', 'reportingPeriod']).sum()\n",
    "df = df.reset_index()\n",
    "df = df.rename(columns = {'reportingPeriod': 'year'})\n",
    "df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset #2 Disaster Declarations by State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>year</th>\n",
       "      <th>num_disasters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AK</td>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AK</td>\n",
       "      <td>2019</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AK</td>\n",
       "      <td>2020</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AK</td>\n",
       "      <td>2021</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AK</td>\n",
       "      <td>2022</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>WV</td>\n",
       "      <td>2024</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>WY</td>\n",
       "      <td>2017</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>WY</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>WY</td>\n",
       "      <td>2020</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>WY</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    state  year  num_disasters\n",
       "0      AK  2018              3\n",
       "1      AK  2019              9\n",
       "2      AK  2020            121\n",
       "3      AK  2021              5\n",
       "4      AK  2022             16\n",
       "..    ...   ...            ...\n",
       "319    WV  2024              5\n",
       "320    WY  2017              4\n",
       "321    WY  2018              2\n",
       "322    WY  2020             51\n",
       "323    WY  2023              1\n",
       "\n",
       "[300 rows x 3 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url2 = 'Data/DisasterDeclarationsSummaries.csv'\n",
    "df2= pd.read_csv(url2)\n",
    "df2 = df2.query('fyDeclared >= 2017') # make sure to include equals so 2017 included\n",
    "df2.sort_values(by = 'fyDeclared', ascending = True) # set to true so make sure have correct info\n",
    "df2 = df2.groupby(by = ['state', 'fyDeclared']).size().reset_index(name= 'num_disasters') # use size for num of disasters instead of sum & give column name\n",
    "df2 = df2.rename(columns={'fyDeclared': 'year'})\n",
    "valid_states = ['AL', 'AK', 'AZ', 'AR', 'CA', 'CO', 'CT', 'DE', 'FL', 'GA', \n",
    "                'HI', 'ID', 'IL', 'IN', 'IA', 'KS', 'KY', 'LA', 'ME', 'MD', \n",
    "                'MA', 'MI', 'MN', 'MS', 'MO', 'MT', 'NE', 'NV', 'NH', 'NJ', \n",
    "                'NM', 'NY', 'NC', 'ND', 'OH', 'OK', 'OR', 'PA', 'RI', 'SC', \n",
    "                'SD', 'TN', 'TX', 'UT', 'VT', 'VA', 'WA', 'WV', 'WI', 'WY']\n",
    "\n",
    "# Filter the DataFrame to only include rows where the state code is in the list of valid states\n",
    "df2 = df2[df2['state'].isin(valid_states)]\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset #3 State Historical Political Leaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ALABAMA', 'ALASKA', 'ARIZONA', 'ARKANSAS', 'CALIFORNIA',\n",
       "       'COLORADO', 'CONNECTICUT', 'DELAWARE', 'DISTRICT OF COLUMBIA',\n",
       "       'FLORIDA', 'GEORGIA', 'HAWAII', 'IDAHO', 'ILLINOIS', 'INDIANA',\n",
       "       'IOWA', 'KANSAS', 'KENTUCKY', 'LOUISIANA', 'MAINE', 'MARYLAND',\n",
       "       'MASSACHUSETTS', 'MICHIGAN', 'MINNESOTA', 'MISSISSIPPI',\n",
       "       'MISSOURI', 'MONTANA', 'NEBRASKA', 'NEVADA', 'NEW HAMPSHIRE',\n",
       "       'NEW JERSEY', 'NEW MEXICO', 'NEW YORK', 'NORTH CAROLINA',\n",
       "       'NORTH DAKOTA', 'OHIO', 'OKLAHOMA', 'OREGON', 'PENNSYLVANIA',\n",
       "       'RHODE ISLAND', 'SOUTH CAROLINA', 'SOUTH DAKOTA', 'TENNESSEE',\n",
       "       'TEXAS', 'UTAH', 'VERMONT', 'VIRGINIA', 'WASHINGTON',\n",
       "       'WEST VIRGINIA', 'WISCONSIN', 'WYOMING'], dtype=object)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url3 = 'Data/1976-2022-house.csv'\n",
    "election_data= pd.read_csv(url3)\n",
    "\n",
    "elections_post_2017 = election_data[election_data['year'] > 2017]\n",
    "relevant_elections = elections_post_2017[elections_post_2017['party'].isin(['DEMOCRAT', 'REPUBLICAN'])]\n",
    "grouped_elections = relevant_elections.groupby(['state', 'year', 'party'])['candidatevotes'].sum().reset_index()\n",
    "winning_party = grouped_elections.sort_values('candidatevotes', ascending=False).drop_duplicates(['state', 'year'])\n",
    "winning_party_by_state_year = winning_party.groupby(['state', 'year'])['party'].first().reset_index()\n",
    "winning_party_by_state_year['state'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset #4 GDP by State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GeoFips</th>\n",
       "      <th>GeoName</th>\n",
       "      <th>2017</th>\n",
       "      <th>2018</th>\n",
       "      <th>2019</th>\n",
       "      <th>2020</th>\n",
       "      <th>2021</th>\n",
       "      <th>2022</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01000</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>216615.5</td>\n",
       "      <td>226263.8</td>\n",
       "      <td>234526.4</td>\n",
       "      <td>235118.3</td>\n",
       "      <td>257986.5</td>\n",
       "      <td>281569.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>02000</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>53550.9</td>\n",
       "      <td>54762.0</td>\n",
       "      <td>54469.9</td>\n",
       "      <td>51261.5</td>\n",
       "      <td>58646.0</td>\n",
       "      <td>65698.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>04000</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>333099.0</td>\n",
       "      <td>353671.0</td>\n",
       "      <td>375545.0</td>\n",
       "      <td>386443.5</td>\n",
       "      <td>432279.8</td>\n",
       "      <td>475653.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>05000</td>\n",
       "      <td>Arkansas</td>\n",
       "      <td>123882.6</td>\n",
       "      <td>129213.8</td>\n",
       "      <td>132637.2</td>\n",
       "      <td>135884.5</td>\n",
       "      <td>151931.9</td>\n",
       "      <td>165989.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>06000</td>\n",
       "      <td>California</td>\n",
       "      <td>2740550.3</td>\n",
       "      <td>2899530.9</td>\n",
       "      <td>3062158.9</td>\n",
       "      <td>3068809.4</td>\n",
       "      <td>3416939.4</td>\n",
       "      <td>3641643.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>08000</td>\n",
       "      <td>Colorado</td>\n",
       "      <td>350209.1</td>\n",
       "      <td>373923.1</td>\n",
       "      <td>397701.6</td>\n",
       "      <td>397612.2</td>\n",
       "      <td>447051.7</td>\n",
       "      <td>491289.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>09000</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>273875.1</td>\n",
       "      <td>280535.4</td>\n",
       "      <td>285466.4</td>\n",
       "      <td>275801.9</td>\n",
       "      <td>295907.5</td>\n",
       "      <td>319344.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10000</td>\n",
       "      <td>Delaware</td>\n",
       "      <td>69555.6</td>\n",
       "      <td>73376.0</td>\n",
       "      <td>78685.8</td>\n",
       "      <td>77615.1</td>\n",
       "      <td>82952.8</td>\n",
       "      <td>90208.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>12000</td>\n",
       "      <td>Florida</td>\n",
       "      <td>1014866.9</td>\n",
       "      <td>1072085.6</td>\n",
       "      <td>1127988.6</td>\n",
       "      <td>1140133.0</td>\n",
       "      <td>1292391.3</td>\n",
       "      <td>1439065.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13000</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>583543.3</td>\n",
       "      <td>612803.4</td>\n",
       "      <td>646939.0</td>\n",
       "      <td>637930.6</td>\n",
       "      <td>701606.1</td>\n",
       "      <td>767377.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>15000</td>\n",
       "      <td>Hawaii</td>\n",
       "      <td>87436.4</td>\n",
       "      <td>90933.5</td>\n",
       "      <td>93356.2</td>\n",
       "      <td>84615.2</td>\n",
       "      <td>93089.8</td>\n",
       "      <td>101082.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>16000</td>\n",
       "      <td>Idaho</td>\n",
       "      <td>72935.1</td>\n",
       "      <td>79072.4</td>\n",
       "      <td>84550.2</td>\n",
       "      <td>88187.7</td>\n",
       "      <td>98792.8</td>\n",
       "      <td>110871.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>17000</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>832826.8</td>\n",
       "      <td>871024.2</td>\n",
       "      <td>895800.0</td>\n",
       "      <td>860747.5</td>\n",
       "      <td>943993.3</td>\n",
       "      <td>1025667.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>18000</td>\n",
       "      <td>Indiana</td>\n",
       "      <td>357535.8</td>\n",
       "      <td>377376.9</td>\n",
       "      <td>385446.2</td>\n",
       "      <td>377901.1</td>\n",
       "      <td>422951.9</td>\n",
       "      <td>470323.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>19000</td>\n",
       "      <td>Iowa</td>\n",
       "      <td>187125.0</td>\n",
       "      <td>193155.1</td>\n",
       "      <td>196085.1</td>\n",
       "      <td>199447.0</td>\n",
       "      <td>220818.2</td>\n",
       "      <td>238342.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>20000</td>\n",
       "      <td>Kansas</td>\n",
       "      <td>166273.6</td>\n",
       "      <td>173373.0</td>\n",
       "      <td>176917.7</td>\n",
       "      <td>177720.6</td>\n",
       "      <td>191831.7</td>\n",
       "      <td>209326.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>21000</td>\n",
       "      <td>Kentucky</td>\n",
       "      <td>203564.0</td>\n",
       "      <td>210509.1</td>\n",
       "      <td>220683.3</td>\n",
       "      <td>218755.2</td>\n",
       "      <td>237925.9</td>\n",
       "      <td>258981.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>22000</td>\n",
       "      <td>Louisiana</td>\n",
       "      <td>239830.7</td>\n",
       "      <td>256444.4</td>\n",
       "      <td>257096.7</td>\n",
       "      <td>236135.9</td>\n",
       "      <td>263162.7</td>\n",
       "      <td>291951.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>23000</td>\n",
       "      <td>Maine</td>\n",
       "      <td>63000.6</td>\n",
       "      <td>66216.0</td>\n",
       "      <td>69298.2</td>\n",
       "      <td>72091.6</td>\n",
       "      <td>78918.4</td>\n",
       "      <td>85801.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>24000</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>399714.5</td>\n",
       "      <td>410771.8</td>\n",
       "      <td>419447.6</td>\n",
       "      <td>413417.7</td>\n",
       "      <td>446941.0</td>\n",
       "      <td>480112.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>25000</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>530129.4</td>\n",
       "      <td>559605.0</td>\n",
       "      <td>588617.5</td>\n",
       "      <td>589033.3</td>\n",
       "      <td>645434.0</td>\n",
       "      <td>691460.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>26000</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>505101.5</td>\n",
       "      <td>525240.8</td>\n",
       "      <td>536975.6</td>\n",
       "      <td>530231.1</td>\n",
       "      <td>576502.2</td>\n",
       "      <td>622562.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>27000</td>\n",
       "      <td>Minnesota</td>\n",
       "      <td>354721.9</td>\n",
       "      <td>372439.2</td>\n",
       "      <td>383961.6</td>\n",
       "      <td>379438.7</td>\n",
       "      <td>413063.1</td>\n",
       "      <td>448032.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>28000</td>\n",
       "      <td>Mississippi</td>\n",
       "      <td>110281.4</td>\n",
       "      <td>113166.4</td>\n",
       "      <td>115441.7</td>\n",
       "      <td>116193.1</td>\n",
       "      <td>128364.5</td>\n",
       "      <td>139976.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>29000</td>\n",
       "      <td>Missouri</td>\n",
       "      <td>311273.8</td>\n",
       "      <td>320451.6</td>\n",
       "      <td>334364.7</td>\n",
       "      <td>335278.3</td>\n",
       "      <td>365145.4</td>\n",
       "      <td>396889.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>30000</td>\n",
       "      <td>Montana</td>\n",
       "      <td>48470.5</td>\n",
       "      <td>51152.1</td>\n",
       "      <td>52772.5</td>\n",
       "      <td>53130.7</td>\n",
       "      <td>59996.7</td>\n",
       "      <td>67071.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>31000</td>\n",
       "      <td>Nebraska</td>\n",
       "      <td>123219.9</td>\n",
       "      <td>127954.4</td>\n",
       "      <td>132741.0</td>\n",
       "      <td>135285.0</td>\n",
       "      <td>149360.3</td>\n",
       "      <td>164933.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>32000</td>\n",
       "      <td>Nevada</td>\n",
       "      <td>163199.1</td>\n",
       "      <td>172547.9</td>\n",
       "      <td>184343.9</td>\n",
       "      <td>175982.0</td>\n",
       "      <td>200127.3</td>\n",
       "      <td>222938.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>33000</td>\n",
       "      <td>New Hampshire</td>\n",
       "      <td>81179.6</td>\n",
       "      <td>83859.4</td>\n",
       "      <td>87472.0</td>\n",
       "      <td>88589.4</td>\n",
       "      <td>99100.0</td>\n",
       "      <td>105024.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>34000</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>590086.7</td>\n",
       "      <td>619340.2</td>\n",
       "      <td>641877.6</td>\n",
       "      <td>630212.7</td>\n",
       "      <td>692227.3</td>\n",
       "      <td>754948.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>35000</td>\n",
       "      <td>New Mexico</td>\n",
       "      <td>93210.1</td>\n",
       "      <td>98838.2</td>\n",
       "      <td>103869.2</td>\n",
       "      <td>100434.5</td>\n",
       "      <td>111730.6</td>\n",
       "      <td>125540.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>36000</td>\n",
       "      <td>New York</td>\n",
       "      <td>1624800.7</td>\n",
       "      <td>1710665.6</td>\n",
       "      <td>1793261.3</td>\n",
       "      <td>1766857.4</td>\n",
       "      <td>1911345.8</td>\n",
       "      <td>2048402.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>37000</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>546810.1</td>\n",
       "      <td>568037.3</td>\n",
       "      <td>593126.9</td>\n",
       "      <td>601148.7</td>\n",
       "      <td>659529.3</td>\n",
       "      <td>715968.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>38000</td>\n",
       "      <td>North Dakota</td>\n",
       "      <td>56530.2</td>\n",
       "      <td>60377.1</td>\n",
       "      <td>60516.3</td>\n",
       "      <td>55347.6</td>\n",
       "      <td>63208.6</td>\n",
       "      <td>72651.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>39000</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>652187.5</td>\n",
       "      <td>672540.1</td>\n",
       "      <td>703127.8</td>\n",
       "      <td>692121.9</td>\n",
       "      <td>759626.2</td>\n",
       "      <td>825990.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>40000</td>\n",
       "      <td>Oklahoma</td>\n",
       "      <td>192538.6</td>\n",
       "      <td>204193.9</td>\n",
       "      <td>205262.6</td>\n",
       "      <td>191653.5</td>\n",
       "      <td>217730.8</td>\n",
       "      <td>242738.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>41000</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>225534.5</td>\n",
       "      <td>238466.9</td>\n",
       "      <td>248939.8</td>\n",
       "      <td>251855.8</td>\n",
       "      <td>275444.0</td>\n",
       "      <td>297308.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>42000</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>754318.0</td>\n",
       "      <td>780620.7</td>\n",
       "      <td>803078.0</td>\n",
       "      <td>777427.1</td>\n",
       "      <td>844391.6</td>\n",
       "      <td>911813.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>44000</td>\n",
       "      <td>Rhode Island</td>\n",
       "      <td>58771.6</td>\n",
       "      <td>60064.9</td>\n",
       "      <td>62526.9</td>\n",
       "      <td>62054.2</td>\n",
       "      <td>67236.7</td>\n",
       "      <td>72771.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>45000</td>\n",
       "      <td>South Carolina</td>\n",
       "      <td>224937.6</td>\n",
       "      <td>236561.7</td>\n",
       "      <td>248046.5</td>\n",
       "      <td>249482.2</td>\n",
       "      <td>271494.5</td>\n",
       "      <td>297546.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>46000</td>\n",
       "      <td>South Dakota</td>\n",
       "      <td>51615.1</td>\n",
       "      <td>53349.5</td>\n",
       "      <td>55007.4</td>\n",
       "      <td>56162.9</td>\n",
       "      <td>62607.1</td>\n",
       "      <td>68781.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>47000</td>\n",
       "      <td>Tennessee</td>\n",
       "      <td>355417.5</td>\n",
       "      <td>369713.2</td>\n",
       "      <td>385819.5</td>\n",
       "      <td>390172.6</td>\n",
       "      <td>438180.0</td>\n",
       "      <td>485657.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>48000</td>\n",
       "      <td>Texas</td>\n",
       "      <td>1667313.0</td>\n",
       "      <td>1808026.9</td>\n",
       "      <td>1860108.3</td>\n",
       "      <td>1798596.1</td>\n",
       "      <td>2087490.9</td>\n",
       "      <td>2402137.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>49000</td>\n",
       "      <td>Utah</td>\n",
       "      <td>172075.0</td>\n",
       "      <td>186805.7</td>\n",
       "      <td>201285.4</td>\n",
       "      <td>205666.3</td>\n",
       "      <td>232125.1</td>\n",
       "      <td>256369.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>50000</td>\n",
       "      <td>Vermont</td>\n",
       "      <td>32589.2</td>\n",
       "      <td>33482.6</td>\n",
       "      <td>34628.1</td>\n",
       "      <td>34470.8</td>\n",
       "      <td>37593.5</td>\n",
       "      <td>40830.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>51000</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>515167.2</td>\n",
       "      <td>537158.3</td>\n",
       "      <td>561989.6</td>\n",
       "      <td>565063.1</td>\n",
       "      <td>613920.3</td>\n",
       "      <td>663105.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>53000</td>\n",
       "      <td>Washington</td>\n",
       "      <td>527169.4</td>\n",
       "      <td>570337.8</td>\n",
       "      <td>608966.4</td>\n",
       "      <td>621493.2</td>\n",
       "      <td>688631.9</td>\n",
       "      <td>738101.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>54000</td>\n",
       "      <td>West Virginia</td>\n",
       "      <td>75172.4</td>\n",
       "      <td>79794.3</td>\n",
       "      <td>79883.8</td>\n",
       "      <td>76975.9</td>\n",
       "      <td>86509.9</td>\n",
       "      <td>97417.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>55000</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>321886.8</td>\n",
       "      <td>335144.3</td>\n",
       "      <td>347398.6</td>\n",
       "      <td>343783.0</td>\n",
       "      <td>369032.4</td>\n",
       "      <td>396209.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>56000</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>37620.3</td>\n",
       "      <td>39614.5</td>\n",
       "      <td>39971.4</td>\n",
       "      <td>36675.5</td>\n",
       "      <td>42176.2</td>\n",
       "      <td>49080.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GeoFips         GeoName       2017       2018       2019       2020  \\\n",
       "1    01000         Alabama   216615.5   226263.8   234526.4   235118.3   \n",
       "2    02000          Alaska    53550.9    54762.0    54469.9    51261.5   \n",
       "3    04000         Arizona   333099.0   353671.0   375545.0   386443.5   \n",
       "4    05000        Arkansas   123882.6   129213.8   132637.2   135884.5   \n",
       "5    06000      California  2740550.3  2899530.9  3062158.9  3068809.4   \n",
       "6    08000        Colorado   350209.1   373923.1   397701.6   397612.2   \n",
       "7    09000     Connecticut   273875.1   280535.4   285466.4   275801.9   \n",
       "8    10000        Delaware    69555.6    73376.0    78685.8    77615.1   \n",
       "10   12000         Florida  1014866.9  1072085.6  1127988.6  1140133.0   \n",
       "11   13000         Georgia   583543.3   612803.4   646939.0   637930.6   \n",
       "12   15000          Hawaii    87436.4    90933.5    93356.2    84615.2   \n",
       "13   16000           Idaho    72935.1    79072.4    84550.2    88187.7   \n",
       "14   17000        Illinois   832826.8   871024.2   895800.0   860747.5   \n",
       "15   18000         Indiana   357535.8   377376.9   385446.2   377901.1   \n",
       "16   19000            Iowa   187125.0   193155.1   196085.1   199447.0   \n",
       "17   20000          Kansas   166273.6   173373.0   176917.7   177720.6   \n",
       "18   21000        Kentucky   203564.0   210509.1   220683.3   218755.2   \n",
       "19   22000       Louisiana   239830.7   256444.4   257096.7   236135.9   \n",
       "20   23000           Maine    63000.6    66216.0    69298.2    72091.6   \n",
       "21   24000        Maryland   399714.5   410771.8   419447.6   413417.7   \n",
       "22   25000   Massachusetts   530129.4   559605.0   588617.5   589033.3   \n",
       "23   26000        Michigan   505101.5   525240.8   536975.6   530231.1   \n",
       "24   27000       Minnesota   354721.9   372439.2   383961.6   379438.7   \n",
       "25   28000     Mississippi   110281.4   113166.4   115441.7   116193.1   \n",
       "26   29000        Missouri   311273.8   320451.6   334364.7   335278.3   \n",
       "27   30000         Montana    48470.5    51152.1    52772.5    53130.7   \n",
       "28   31000        Nebraska   123219.9   127954.4   132741.0   135285.0   \n",
       "29   32000          Nevada   163199.1   172547.9   184343.9   175982.0   \n",
       "30   33000   New Hampshire    81179.6    83859.4    87472.0    88589.4   \n",
       "31   34000      New Jersey   590086.7   619340.2   641877.6   630212.7   \n",
       "32   35000      New Mexico    93210.1    98838.2   103869.2   100434.5   \n",
       "33   36000        New York  1624800.7  1710665.6  1793261.3  1766857.4   \n",
       "34   37000  North Carolina   546810.1   568037.3   593126.9   601148.7   \n",
       "35   38000    North Dakota    56530.2    60377.1    60516.3    55347.6   \n",
       "36   39000            Ohio   652187.5   672540.1   703127.8   692121.9   \n",
       "37   40000        Oklahoma   192538.6   204193.9   205262.6   191653.5   \n",
       "38   41000          Oregon   225534.5   238466.9   248939.8   251855.8   \n",
       "39   42000    Pennsylvania   754318.0   780620.7   803078.0   777427.1   \n",
       "40   44000    Rhode Island    58771.6    60064.9    62526.9    62054.2   \n",
       "41   45000  South Carolina   224937.6   236561.7   248046.5   249482.2   \n",
       "42   46000    South Dakota    51615.1    53349.5    55007.4    56162.9   \n",
       "43   47000       Tennessee   355417.5   369713.2   385819.5   390172.6   \n",
       "44   48000           Texas  1667313.0  1808026.9  1860108.3  1798596.1   \n",
       "45   49000            Utah   172075.0   186805.7   201285.4   205666.3   \n",
       "46   50000         Vermont    32589.2    33482.6    34628.1    34470.8   \n",
       "47   51000        Virginia   515167.2   537158.3   561989.6   565063.1   \n",
       "48   53000      Washington   527169.4   570337.8   608966.4   621493.2   \n",
       "49   54000   West Virginia    75172.4    79794.3    79883.8    76975.9   \n",
       "50   55000       Wisconsin   321886.8   335144.3   347398.6   343783.0   \n",
       "51   56000         Wyoming    37620.3    39614.5    39971.4    36675.5   \n",
       "\n",
       "         2021       2022  \n",
       "1    257986.5   281569.0  \n",
       "2     58646.0    65698.8  \n",
       "3    432279.8   475653.7  \n",
       "4    151931.9   165989.3  \n",
       "5   3416939.4  3641643.4  \n",
       "6    447051.7   491289.0  \n",
       "7    295907.5   319344.8  \n",
       "8     82952.8    90208.3  \n",
       "10  1292391.3  1439065.0  \n",
       "11   701606.1   767377.6  \n",
       "12    93089.8   101082.6  \n",
       "13    98792.8   110871.1  \n",
       "14   943993.3  1025667.2  \n",
       "15   422951.9   470323.6  \n",
       "16   220818.2   238342.3  \n",
       "17   191831.7   209326.1  \n",
       "18   237925.9   258981.2  \n",
       "19   263162.7   291951.9  \n",
       "20    78918.4    85801.2  \n",
       "21   446941.0   480112.7  \n",
       "22   645434.0   691460.6  \n",
       "23   576502.2   622562.7  \n",
       "24   413063.1   448032.4  \n",
       "25   128364.5   139976.4  \n",
       "26   365145.4   396889.9  \n",
       "27    59996.7    67071.9  \n",
       "28   149360.3   164933.9  \n",
       "29   200127.3   222938.6  \n",
       "30    99100.0   105024.6  \n",
       "31   692227.3   754948.2  \n",
       "32   111730.6   125540.6  \n",
       "33  1911345.8  2048402.6  \n",
       "34   659529.3   715968.3  \n",
       "35    63208.6    72651.3  \n",
       "36   759626.2   825990.0  \n",
       "37   217730.8   242738.5  \n",
       "38   275444.0   297308.9  \n",
       "39   844391.6   911813.3  \n",
       "40    67236.7    72771.4  \n",
       "41   271494.5   297546.3  \n",
       "42    62607.1    68781.7  \n",
       "43   438180.0   485657.5  \n",
       "44  2087490.9  2402137.2  \n",
       "45   232125.1   256369.9  \n",
       "46    37593.5    40830.8  \n",
       "47   613920.3   663105.5  \n",
       "48   688631.9   738101.4  \n",
       "49    86509.9    97417.3  \n",
       "50   369032.4   396209.3  \n",
       "51    42176.2    49080.6  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Log onto the BEA website (Bureau of Economic Analysis), the official site for government data.\n",
    "# Navigate to the \"Data\" section, select \"GDP,\" and then choose \"GDP by State.\"\n",
    "# Go to \"Interactive Data\" and select \"Interactive Tables: GDP by State.\"\n",
    "# Choose \"ANNUAL GROSS DOMESTIC PRODUCT (GDP) BY STATE,\" then \"SAGDP2 GDP in current dollars.\"\n",
    "# Select the United States, and view all statistics in the table.\n",
    "# In the resulting table, select the first row's line code where the description is \"all industry total.\"\n",
    "# The resulting table displays the GDP by state in millions of current dollars, with data collected from 2017 to 2022.\n",
    "\n",
    "url4 =  \"Data/GDP by state (2017-2022).csv\"\n",
    "\n",
    "df4 = pd.read_csv(url4, skiprows = 3) #skip first 3 rows because they are a description\n",
    "df4_bad_GeoName = df4['GeoName'].str.contains('District of Columbia|New England|nited States *|Mideast|Great Lakes|Plains|Southeast|Southwest|nan|Rocky Mountain|Far West').fillna(False) #dealing with NA values\n",
    "df4 = df4[~ df4_bad_GeoName] #this removes all the regions and territories we don't care about \n",
    "indexes_to_drop = df4.iloc[-4:].index #get the last 4 rows index using iloc\n",
    "df4 = df4.drop(indexes_to_drop)\n",
    "df4['GeoName'].unique().size # check to see that we only have 50 values for all 50 states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ethics & Privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data is sourced from governmental agencies and nonprofit organizations such as USA Facts, FEMA, and BEA.gov. These sources aim to provide a strictly non-partisan outlook on the actions of the federal government in an effort to promote a pillar of government so necessary to any government's foundation - transparency. These sources do not contain any private data, as any data determined to be accessible to the public by the Freedom of Information act forgoes data which would be deemed a breach of privacy. Our research does not aim to harm any particular population within a county or state, as it is focused on compiling and analyzing the financial aspect of the relationship between state and federal governments. Moreover, decisions on federal funding are guided by uniform, pre-established standards, and commitments, all found within the constitution of the United States. Our compilation of statistical information lacks sufficient means to overturn the nature of this centuries old relation. Electoral data analyzed is on a strictly state-level basis, meaning that we do not utilize a voter's personal information. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team Expectations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* *Be Communicative* - Communicate any difficulties ahead of time! If assistance is needed, or maybe if a team member is unable to do/finish what they need to do, communicating it ahead of time will allow others to help expedite the process.\n",
    "\n",
    "* *Contribute Fairly* - Uphold the responsibilities assigned or taken up by each individual group member, but also keep in mind to make key decisions as a group. \n",
    "\n",
    "* *Communication Guideline* - Communicate primarily through Discord and attend scheduled weekly/bi-weekly calls. Most, if not all calls will be virtual, but be present and be involved in the project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Timeline Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Meeting Date | Meeting Time | Completed Before Meeting      | Discuss at Meeting                                                                 |\n",
    "|--------------|--------------|-------------------------------|------------------------------------------------------------------------------------|\n",
    "| 2/4          | 6 PM         | Read Previous COGS 108 Projects | Discussed the strengths and weaknesses of two COGS 108 projects made by previous groups and noted things to keep and leave in our projects. |\n",
    "| 2/8          | 3 PM         | Research Question              | Discuss hypothesis, research question, project timeline proposal                   |\n",
    "| 2/11         | 6 PM         | Work on Project Proposal       | Discuss hypothesis, research question, project timeline proposal                   |\n",
    "| 2/19         | 7 PM         | Find Relevant Data             | Choose which data we found best fits our research purposes                         |\n",
    "| 2/22         | 8:30 PM      | Categorize Relevant Data       | Discuss what kind of further questions we want to ask within our research question |\n",
    "| 3/4          | 7 PM         | Work on individual categories  | Review and discuss progress                                                        |\n",
    "| 3/7          | 7 PM         | Work on individual categories  | Review and discuss progress                                                        |\n",
    "| 3/14         | 7 PM         | Work on individual categories  | Review and discuss progress                                                        |\n",
    "| 3/17         | 7 PM         | Work on individual categories  | Review and discuss progress                                                        |\n",
    "| 3/20         | Before 11:59\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
